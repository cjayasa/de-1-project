{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb080cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import csv\n",
    "\n",
    "# Define the function to convert an HDF5 file to a list of rows\n",
    "def hdf5_to_rows(input_path):\n",
    "    # Open the HDF5 file\n",
    "    h5 = h5py.File(input_path, 'r')\n",
    "\n",
    "    # Get the table of song metadata\n",
    "    metadata_table = h5['/metadata/songs']\n",
    "\n",
    "    # Loop over each row in the metadata table and convert it to a list of values\n",
    "    rows = []\n",
    "    for row in metadata_table:\n",
    "        rows.append([row[field].decode('utf-8') if isinstance(row[field], bytes) else row[field] for field in metadata_table.dtype.names])\n",
    "\n",
    "    # Close the HDF5 file\n",
    "    h5.close()\n",
    "\n",
    "    return rows\n",
    "\n",
    "# Define the function to recursively search for HDF5 files in a directory and its subdirectories\n",
    "def find_hdf5_files(directory):\n",
    "    # Create an empty list to hold the file paths\n",
    "    file_paths = []\n",
    "\n",
    "    # Loop over each item in the directory\n",
    "    for item in os.listdir(directory):\n",
    "        # Get the full path of the item\n",
    "        item_path = os.path.join(directory, item)\n",
    "\n",
    "        # If the item is a directory, recursively call this function on it\n",
    "        if os.path.isdir(item_path):\n",
    "            file_paths.extend(find_hdf5_files(item_path))\n",
    "\n",
    "        # If the item is an HDF5 file, add its path to the list\n",
    "        elif os.path.isfile(item_path) and item_path.endswith('.h5'):\n",
    "            file_paths.append(item_path)\n",
    "\n",
    "    return file_paths\n",
    "\n",
    "# Define the function to write the metadata for all songs to a CSV file\n",
    "def write_metadata_to_csv(directory, output_path):\n",
    "    # Find all HDF5 files in the directory and its subdirectories\n",
    "    hdf5_files = find_hdf5_files(directory)\n",
    "\n",
    "    # Create an empty list to hold the rows of metadata\n",
    "    rows = []\n",
    "\n",
    "    # Loop over each HDF5 file and convert it to a list of rows\n",
    "    for hdf5_file in hdf5_files:\n",
    "        rows.extend(hdf5_to_rows(hdf5_file))\n",
    "\n",
    "    # Open the output CSV file\n",
    "    with open(output_path, 'w') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "\n",
    "        # Write the header row with all available metadata fields\n",
    "        writer.writerow(['artist_name', 'title', 'release', 'year', 'track_7digitalid', 'shs_perf', 'shs_work', 'song_hotttnesss', 'artist_hotttnesss', 'duration', 'end_of_fade_in', 'start_of_fade_out', 'loudness', 'tempo', 'key', 'key_confidence', 'mode', 'mode_confidence', 'time_signature', 'time_signature_confidence'])\n",
    "        #writer.writerow([    'artist_name',    'artist_id',    'artist_mbid',    'artist_playmeid',    'release',    'release_7digitalid',    'song_id',    'song_hotttnesss',    'title',    'track_7digitalid',    'analysis_sample_rate',    'audio_md5',    'danceability',    'duration',    'end_of_fade_in',    'energy',    'key',    'key_confidence',    'loudness',    'mode',    'mode_confidence',    'start_of_fade_out',    'tempo',    'time_signature',    'time_signature_confidence',    'track_id',    'segments_start',    'segments_confidence',    'segments_pitches',    'segments_timbre',    'segments_loudness_max',    'segments_loudness_max_time',    'segments_loudness_start',    'sections_start',    'sections_confidence',    'beats_start',    'beats_confidence',    'bars_start',    'bars_confidence',    'tatums_start',    'tatums_confidence',    'year'])\n",
    "\n",
    "        \n",
    "        # Write the rows of metadata to the CSV file\n",
    "        for row in rows:\n",
    "            writer.writerow(row)\n",
    "\n",
    "# Call the function to write the metadata for all songs to a CSV file\n",
    "write_metadata_to_csv('/home/ubuntu/data/MillionSongSubset', '/home/ubuntu/data/output.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
