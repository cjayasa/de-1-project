{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f63732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import hdf5_getters\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c95f40df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_artist_familiarity(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_familiarity(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_familiarity.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_artist_hotttnesss(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_hotttnesss(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_hotttnesss.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_artist_id(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_id(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_id.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_artist_mbid(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_mbid(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_mbid.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_artist_playmeid(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_playmeid(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_playmeid.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_artist_7digitalid(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_7digitalid(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_7digitalid.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_artist_latitude(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_latitude(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_latitude.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_artist_longitude(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_longitude(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_longitude.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_artist_location(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_location(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_location.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_artist_name(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_name(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_name.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_release(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_release(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('release.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_release_7digitalid(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_release_7digitalid(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('release_7digitalid.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_song_id(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_song_id(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('song_id.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_song_hotttnesss(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_song_hotttnesss(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('song_hotttnesss.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_title(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_title(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('title.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_track_7digitalid(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_track_7digitalid(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('track_7digitalid.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_similar_artists(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_similar_artists(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('similar_artists.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_artist_terms(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_terms(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_terms.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_artist_terms_freq(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_terms_freq(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_terms_freq.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_artist_terms_weight(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_terms_weight(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_terms_weight.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_analysis_sample_rate(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_analysis_sample_rate(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('analysis_sample_rate.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_audio_md5(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_audio_md5(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('audio_md5.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_danceability(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_danceability(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('danceability.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_duration(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_duration(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('duration.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_end_of_fade_in(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_end_of_fade_in(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('end_of_fade_in.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_energy(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_energy(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('energy.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_key(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_key(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('key.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_key_confidence(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_key_confidence(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('key_confidence.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_loudness(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_loudness(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('loudness.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_mode(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_mode(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('mode.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_mode_confidence(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_mode_confidence(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('mode_confidence.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_start_of_fade_out(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_start_of_fade_out(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('start_of_fade_out.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_tempo(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_tempo(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('tempo.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_time_signature(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_time_signature(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('time_signature.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_time_signature_confidence(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_time_signature_confidence(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('time_signature_confidence.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_track_id(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_track_id(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('track_id.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_segments_start(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_segments_start(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('segments_start.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_segments_confidence(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_segments_confidence(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('segments_confidence.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_segments_pitches(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_segments_pitches(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('segments_pitches.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_segments_timbre(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_segments_timbre(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('segments_timbre.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_segments_loudness_max(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_segments_loudness_max(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('segments_loudness_max.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_segments_loudness_max_time(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_segments_loudness_max_time(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('segments_loudness_max_time.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_segments_loudness_start(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_segments_loudness_start(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('segments_loudness_start.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_sections_start(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_sections_start(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('sections_start.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_sections_confidence(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_sections_confidence(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('sections_confidence.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_beats_start(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_beats_start(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('beats_start.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_beats_confidence(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_beats_confidence(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('beats_confidence.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_bars_start(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_bars_start(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('bars_start.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_bars_confidence(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_bars_confidence(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('bars_confidence.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_tatums_start(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_tatums_start(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('tatums_start.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_tatums_confidence(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_tatums_confidence(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('tatums_confidence.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_artist_mbtags(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_mbtags(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_mbtags.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "        \n",
    "def get_all_artist_mbtags_count(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_artist_mbtags_count(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('artist_mbtags_count.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])\n",
    "    \n",
    "def get_all_year(basedir,ext='.h5') :\n",
    "    items = []\n",
    "    for root, dirs, files in os.walk(basedir):\n",
    "        files = glob.glob(os.path.join(root,'*'+ext))\n",
    "        for f in files:\n",
    "            h5 = hdf5_getters.open_h5_file_read(f)\n",
    "            items.append( hdf5_getters.get_year(h5) )\n",
    "            h5.close()\n",
    "    print(len(items))\n",
    "    with open('year.csv', 'w', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows([[item] for item in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c415fc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_artist_familiarity('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_hotttnesss('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_id('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_mbid('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_playmeid('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_7digitalid('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_latitude('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_longitude('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_location('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_name('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_release('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_release_7digitalid('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_song_id('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_song_hotttnesss('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_title('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_track_7digitalid('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_similar_artists('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_terms('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_terms_freq('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_terms_weight('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_analysis_sample_rate('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_audio_md5('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_danceability('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_duration('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_end_of_fade_in('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_energy('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_key('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_key_confidence('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_loudness('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_mode('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_mode_confidence('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_start_of_fade_out('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_tempo('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_time_signature('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_time_signature_confidence('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_track_id('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_segments_start('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_segments_confidence('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_segments_pitches('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_segments_timbre('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_segments_loudness_max('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_segments_loudness_max_time('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_segments_loudness_start('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_sections_start('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_sections_confidence('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_beats_start('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_beats_confidence('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_bars_start('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_bars_confidence('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_tatums_start('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_tatums_confidence('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_mbtags('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_artist_mbtags_count('/home/ubuntu/data/MillionSongSubset')\n",
    "get_all_year('/home/ubuntu/data/MillionSongSubset')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
